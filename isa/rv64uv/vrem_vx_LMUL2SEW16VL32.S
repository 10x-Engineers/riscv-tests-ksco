
# See LICENSE for license details.

# This file is automatically generated. Do not edit.

#*****************************************************************************
# vrem_vx_LMUL2SEW16VL32.S
#-----------------------------------------------------------------------------
#
# Test vrem.vx instructions.
# With LMUL=2, SEW=16, VL=32
#

#include "riscv_test.h"
#include "test_macros.h"

RVTEST_RV64UV

RVTEST_CODE_BEGIN


  li t0, -1
  vsetvli t1, t0, e16,m2,ta,ma
  la a2, tdat
  vle16.v v4, (a2)
  vle16.v v2, (a2)

  
  li t0, 32
  vsetvli t1, t0, e16,m2,ta,ma
  li t2, 1
  vrem.vx v2, v4, t2

  li t0, -1
  vsetvli t1, t0, e16,m2,ta,ma
  la a1, res
  vse16.v v2, (a1)
  la a2, sres

  TEST_CASE(2, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(3, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(4, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(5, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(6, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(7, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(8, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(9, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)



  li t0, -1
  vsetvli t1, t0, e16,m2,ta,ma
  la a2, tdat
  vle16.v v4, (a2)
  vle16.v v2, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 32
  vsetvli t1, t0, e16,m2,ta,ma
  li t2, 1
  vrem.vx v2, v4, t2, v0.t

  li t0, -1
  vsetvli t1, t0, e16,m2,ta,ma
  la a1, res
  vse16.v v2, (a1)
  la a2, sres


  TEST_CASE(10, t0, 0x30000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(11, t0, 0x70000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(12, t0, 0xffff0000efff0000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(13, t0, 0x1000000010000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(14, t0, 0x30000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(15, t0, 0x70000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(16, t0, 0xffff0000efff0000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(17, t0, 0x1000000010000, ld t0, 0(a1); addi a1, a1, 8)



  li t0, -1
  vsetvli t1, t0, e16,m2,ta,ma
  la a2, tdat
  vle16.v v4, (a2)
  vle16.v v2, (a2)

  
  li t0, 32
  vsetvli t1, t0, e16,m2,tu,ma
  li t2, 1
  vrem.vx v2, v4, t2

  li t0, -1
  vsetvli t1, t0, e16,m2,ta,ma
  la a1, res
  vse16.v v2, (a1)
  la a2, sres


  TEST_CASE(18, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(19, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(20, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(21, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(22, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(23, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(24, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(25, t0, 0x0, ld t0, 0(a1); addi a1, a1, 8)



  li t0, -1
  vsetvli t1, t0, e16,m2,ta,ma
  la a2, tdat
  vle16.v v4, (a2)
  vle16.v v2, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 32
  vsetvli t1, t0, e16,m2,ta,ma
  li t2, 1
  vrem.vx v2, v4, t2, v0.t

  li t0, -1
  vsetvli t1, t0, e16,m2,ta,ma
  la a1, res
  vse16.v v2, (a1)
  la a2, sres


  TEST_CASE(26, t0, 0x30000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(27, t0, 0x70000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(28, t0, 0xffff0000efff0000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(29, t0, 0x1000000010000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(30, t0, 0x30000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(31, t0, 0x70000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(32, t0, 0xffff0000efff0000, ld t0, 0(a1); addi a1, a1, 8)
  TEST_CASE(33, t0, 0x1000000010000, ld t0, 0(a1); addi a1, a1, 8)




  TEST_PASSFAIL

RVTEST_CODE_END

  .data
RVTEST_DATA_BEGIN

res:
  .zero 72

sres:
  .zero 72

tdat:
  .quad 0x10003fff8
  .quad 0x100070000
  .quad 0xffffefffefffffff
  .quad 0x1000000010000
  .quad 0x10003fff8
  .quad 0x100070000
  .quad 0xffffefffefffffff
  .quad 0x1000000010000
  .quad 0x10003fff8

mask:
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555

RVTEST_DATA_END
