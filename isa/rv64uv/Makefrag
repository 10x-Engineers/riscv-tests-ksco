
#=======================================================================
# Makefrag for rv64uv tests
#-----------------------------------------------------------------------

rv64uv_sc_tests = \
  vadc.vim_LMUL1SEW16 \
  vadc.vim_LMUL1SEW32 \
  vadc.vim_LMUL1SEW64 \
  vadc.vim_LMUL1SEW8 \
  vadc.vim_LMUL2SEW16 \
  vadc.vim_LMUL2SEW32 \
  vadc.vim_LMUL2SEW64 \
  vadc.vim_LMUL2SEW8 \
  vadc.vim_LMUL4SEW16 \
  vadc.vim_LMUL4SEW32 \
  vadc.vim_LMUL4SEW64 \
  vadc.vim_LMUL4SEW8 \
  vadc.vim_LMUL8SEW16 \
  vadc.vim_LMUL8SEW32 \
  vadc.vim_LMUL8SEW64 \
  vadc.vim_LMUL8SEW8 \
  vadc.vvm_LMUL1SEW16 \
  vadc.vvm_LMUL1SEW32 \
  vadc.vvm_LMUL1SEW64 \
  vadc.vvm_LMUL1SEW8 \
  vadc.vvm_LMUL2SEW16 \
  vadc.vvm_LMUL2SEW32 \
  vadc.vvm_LMUL2SEW64 \
  vadc.vvm_LMUL2SEW8 \
  vadc.vvm_LMUL4SEW16 \
  vadc.vvm_LMUL4SEW32 \
  vadc.vvm_LMUL4SEW64 \
  vadc.vvm_LMUL4SEW8 \
  vadc.vvm_LMUL8SEW16 \
  vadc.vvm_LMUL8SEW32 \
  vadc.vvm_LMUL8SEW64 \
  vadc.vvm_LMUL8SEW8 \
  vadc.vxm_LMUL1SEW16 \
  vadc.vxm_LMUL1SEW32 \
  vadc.vxm_LMUL1SEW64 \
  vadc.vxm_LMUL1SEW8 \
  vadc.vxm_LMUL2SEW16 \
  vadc.vxm_LMUL2SEW32 \
  vadc.vxm_LMUL2SEW64 \
  vadc.vxm_LMUL2SEW8 \
  vadc.vxm_LMUL4SEW16 \
  vadc.vxm_LMUL4SEW32 \
  vadc.vxm_LMUL4SEW64 \
  vadc.vxm_LMUL4SEW8 \
  vadc.vxm_LMUL8SEW16 \
  vadc.vxm_LMUL8SEW32 \
  vadc.vxm_LMUL8SEW64 \
  vadc.vxm_LMUL8SEW8 \
  vadd.vi_LMUL1SEW16 \
  vadd.vi_LMUL1SEW32 \
  vadd.vi_LMUL1SEW64 \
  vadd.vi_LMUL1SEW8 \
  vadd.vi_LMUL2SEW16 \
  vadd.vi_LMUL2SEW32 \
  vadd.vi_LMUL2SEW64 \
  vadd.vi_LMUL2SEW8 \
  vadd.vi_LMUL4SEW16 \
  vadd.vi_LMUL4SEW32 \
  vadd.vi_LMUL4SEW64 \
  vadd.vi_LMUL4SEW8 \
  vadd.vi_LMUL8SEW16 \
  vadd.vi_LMUL8SEW32 \
  vadd.vi_LMUL8SEW64 \
  vadd.vi_LMUL8SEW8 \
  vadd.vv_LMUL1SEW16 \
  vadd.vv_LMUL1SEW32 \
  vadd.vv_LMUL1SEW64 \
  vadd.vv_LMUL1SEW8 \
  vadd.vv_LMUL2SEW16 \
  vadd.vv_LMUL2SEW32 \
  vadd.vv_LMUL2SEW64 \
  vadd.vv_LMUL2SEW8 \
  vadd.vv_LMUL4SEW16 \
  vadd.vv_LMUL4SEW32 \
  vadd.vv_LMUL4SEW64 \
  vadd.vv_LMUL4SEW8 \
  vadd.vv_LMUL8SEW16 \
  vadd.vv_LMUL8SEW32 \
  vadd.vv_LMUL8SEW64 \
  vadd.vv_LMUL8SEW8 \
  vadd.vx_LMUL1SEW16 \
  vadd.vx_LMUL1SEW32 \
  vadd.vx_LMUL1SEW64 \
  vadd.vx_LMUL1SEW8 \
  vadd.vx_LMUL2SEW16 \
  vadd.vx_LMUL2SEW32 \
  vadd.vx_LMUL2SEW64 \
  vadd.vx_LMUL2SEW8 \
  vadd.vx_LMUL4SEW16 \
  vadd.vx_LMUL4SEW32 \
  vadd.vx_LMUL4SEW64 \
  vadd.vx_LMUL4SEW8 \
  vadd.vx_LMUL8SEW16 \
  vadd.vx_LMUL8SEW32 \
  vadd.vx_LMUL8SEW64 \
  vadd.vx_LMUL8SEW8 \
  vand.vi_LMUL1SEW16 \
  vand.vi_LMUL1SEW32 \
  vand.vi_LMUL1SEW64 \
  vand.vi_LMUL1SEW8 \
  vand.vi_LMUL2SEW16 \
  vand.vi_LMUL2SEW32 \
  vand.vi_LMUL2SEW64 \
  vand.vi_LMUL2SEW8 \
  vand.vi_LMUL4SEW16 \
  vand.vi_LMUL4SEW32 \
  vand.vi_LMUL4SEW64 \
  vand.vi_LMUL4SEW8 \
  vand.vi_LMUL8SEW16 \
  vand.vi_LMUL8SEW32 \
  vand.vi_LMUL8SEW64 \
  vand.vi_LMUL8SEW8 \
  vand.vv_LMUL1SEW16 \
  vand.vv_LMUL1SEW32 \
  vand.vv_LMUL1SEW64 \
  vand.vv_LMUL1SEW8 \
  vand.vv_LMUL2SEW16 \
  vand.vv_LMUL2SEW32 \
  vand.vv_LMUL2SEW64 \
  vand.vv_LMUL2SEW8 \
  vand.vv_LMUL4SEW16 \
  vand.vv_LMUL4SEW32 \
  vand.vv_LMUL4SEW64 \
  vand.vv_LMUL4SEW8 \
  vand.vv_LMUL8SEW16 \
  vand.vv_LMUL8SEW32 \
  vand.vv_LMUL8SEW64 \
  vand.vv_LMUL8SEW8 \
  vand.vx_LMUL1SEW16 \
  vand.vx_LMUL1SEW32 \
  vand.vx_LMUL1SEW64 \
  vand.vx_LMUL1SEW8 \
  vand.vx_LMUL2SEW16 \
  vand.vx_LMUL2SEW32 \
  vand.vx_LMUL2SEW64 \
  vand.vx_LMUL2SEW8 \
  vand.vx_LMUL4SEW16 \
  vand.vx_LMUL4SEW32 \
  vand.vx_LMUL4SEW64 \
  vand.vx_LMUL4SEW8 \
  vand.vx_LMUL8SEW16 \
  vand.vx_LMUL8SEW32 \
  vand.vx_LMUL8SEW64 \
  vand.vx_LMUL8SEW8 \
  vdiv.vv_LMUL1SEW16 \
  vdiv.vv_LMUL1SEW32 \
  vdiv.vv_LMUL1SEW64 \
  vdiv.vv_LMUL1SEW8 \
  vdiv.vv_LMUL2SEW16 \
  vdiv.vv_LMUL2SEW32 \
  vdiv.vv_LMUL2SEW64 \
  vdiv.vv_LMUL2SEW8 \
  vdiv.vv_LMUL4SEW16 \
  vdiv.vv_LMUL4SEW32 \
  vdiv.vv_LMUL4SEW64 \
  vdiv.vv_LMUL4SEW8 \
  vdiv.vv_LMUL8SEW16 \
  vdiv.vv_LMUL8SEW32 \
  vdiv.vv_LMUL8SEW64 \
  vdiv.vv_LMUL8SEW8 \
  vdiv.vx_LMUL1SEW16 \
  vdiv.vx_LMUL1SEW32 \
  vdiv.vx_LMUL1SEW64 \
  vdiv.vx_LMUL1SEW8 \
  vdiv.vx_LMUL2SEW16 \
  vdiv.vx_LMUL2SEW32 \
  vdiv.vx_LMUL2SEW64 \
  vdiv.vx_LMUL2SEW8 \
  vdiv.vx_LMUL4SEW16 \
  vdiv.vx_LMUL4SEW32 \
  vdiv.vx_LMUL4SEW64 \
  vdiv.vx_LMUL4SEW8 \
  vdiv.vx_LMUL8SEW16 \
  vdiv.vx_LMUL8SEW32 \
  vdiv.vx_LMUL8SEW64 \
  vdiv.vx_LMUL8SEW8 \
  vdivu.vv_LMUL1SEW16 \
  vdivu.vv_LMUL1SEW32 \
  vdivu.vv_LMUL1SEW64 \
  vdivu.vv_LMUL1SEW8 \
  vdivu.vv_LMUL2SEW16 \
  vdivu.vv_LMUL2SEW32 \
  vdivu.vv_LMUL2SEW64 \
  vdivu.vv_LMUL2SEW8 \
  vdivu.vv_LMUL4SEW16 \
  vdivu.vv_LMUL4SEW32 \
  vdivu.vv_LMUL4SEW64 \
  vdivu.vv_LMUL4SEW8 \
  vdivu.vv_LMUL8SEW16 \
  vdivu.vv_LMUL8SEW32 \
  vdivu.vv_LMUL8SEW64 \
  vdivu.vv_LMUL8SEW8 \
  vdivu.vx_LMUL1SEW16 \
  vdivu.vx_LMUL1SEW32 \
  vdivu.vx_LMUL1SEW64 \
  vdivu.vx_LMUL1SEW8 \
  vdivu.vx_LMUL2SEW16 \
  vdivu.vx_LMUL2SEW32 \
  vdivu.vx_LMUL2SEW64 \
  vdivu.vx_LMUL2SEW8 \
  vdivu.vx_LMUL4SEW16 \
  vdivu.vx_LMUL4SEW32 \
  vdivu.vx_LMUL4SEW64 \
  vdivu.vx_LMUL4SEW8 \
  vdivu.vx_LMUL8SEW16 \
  vdivu.vx_LMUL8SEW32 \
  vdivu.vx_LMUL8SEW64 \
  vdivu.vx_LMUL8SEW8 \
  vfadd.vf_LMUL1SEW32 \
  vfadd.vf_LMUL1SEW64 \
  vfadd.vf_LMUL2SEW32 \
  vfadd.vf_LMUL2SEW64 \
  vfadd.vf_LMUL4SEW32 \
  vfadd.vf_LMUL4SEW64 \
  vfadd.vf_LMUL8SEW32 \
  vfadd.vf_LMUL8SEW64 \
  vfadd.vv_LMUL1SEW32 \
  vfadd.vv_LMUL1SEW64 \
  vfadd.vv_LMUL2SEW32 \
  vfadd.vv_LMUL2SEW64 \
  vfadd.vv_LMUL4SEW32 \
  vfadd.vv_LMUL4SEW64 \
  vfadd.vv_LMUL8SEW32 \
  vfadd.vv_LMUL8SEW64 \
  vfmax.vf_LMUL1SEW32 \
  vfmax.vf_LMUL1SEW64 \
  vfmax.vf_LMUL2SEW32 \
  vfmax.vf_LMUL2SEW64 \
  vfmax.vf_LMUL4SEW32 \
  vfmax.vf_LMUL4SEW64 \
  vfmax.vf_LMUL8SEW32 \
  vfmax.vf_LMUL8SEW64 \
  vfmax.vv_LMUL1SEW32 \
  vfmax.vv_LMUL1SEW64 \
  vfmax.vv_LMUL2SEW32 \
  vfmax.vv_LMUL2SEW64 \
  vfmax.vv_LMUL4SEW32 \
  vfmax.vv_LMUL4SEW64 \
  vfmax.vv_LMUL8SEW32 \
  vfmax.vv_LMUL8SEW64 \
  vfmin.vf_LMUL1SEW32 \
  vfmin.vf_LMUL1SEW64 \
  vfmin.vf_LMUL2SEW32 \
  vfmin.vf_LMUL2SEW64 \
  vfmin.vf_LMUL4SEW32 \
  vfmin.vf_LMUL4SEW64 \
  vfmin.vf_LMUL8SEW32 \
  vfmin.vf_LMUL8SEW64 \
  vfmin.vv_LMUL1SEW32 \
  vfmin.vv_LMUL1SEW64 \
  vfmin.vv_LMUL2SEW32 \
  vfmin.vv_LMUL2SEW64 \
  vfmin.vv_LMUL4SEW32 \
  vfmin.vv_LMUL4SEW64 \
  vfmin.vv_LMUL8SEW32 \
  vfmin.vv_LMUL8SEW64 \
  vfsgnj.vf_LMUL1SEW32 \
  vfsgnj.vf_LMUL1SEW64 \
  vfsgnj.vf_LMUL2SEW32 \
  vfsgnj.vf_LMUL2SEW64 \
  vfsgnj.vf_LMUL4SEW32 \
  vfsgnj.vf_LMUL4SEW64 \
  vfsgnj.vf_LMUL8SEW32 \
  vfsgnj.vf_LMUL8SEW64 \
  vfsgnj.vv_LMUL1SEW32 \
  vfsgnj.vv_LMUL1SEW64 \
  vfsgnj.vv_LMUL2SEW32 \
  vfsgnj.vv_LMUL2SEW64 \
  vfsgnj.vv_LMUL4SEW32 \
  vfsgnj.vv_LMUL4SEW64 \
  vfsgnj.vv_LMUL8SEW32 \
  vfsgnj.vv_LMUL8SEW64 \
  vfsgnjn.vf_LMUL1SEW32 \
  vfsgnjn.vf_LMUL1SEW64 \
  vfsgnjn.vf_LMUL2SEW32 \
  vfsgnjn.vf_LMUL2SEW64 \
  vfsgnjn.vf_LMUL4SEW32 \
  vfsgnjn.vf_LMUL4SEW64 \
  vfsgnjn.vf_LMUL8SEW32 \
  vfsgnjn.vf_LMUL8SEW64 \
  vfsgnjn.vv_LMUL1SEW32 \
  vfsgnjn.vv_LMUL1SEW64 \
  vfsgnjn.vv_LMUL2SEW32 \
  vfsgnjn.vv_LMUL2SEW64 \
  vfsgnjn.vv_LMUL4SEW32 \
  vfsgnjn.vv_LMUL4SEW64 \
  vfsgnjn.vv_LMUL8SEW32 \
  vfsgnjn.vv_LMUL8SEW64 \
  vfsgnjx.vf_LMUL1SEW32 \
  vfsgnjx.vf_LMUL1SEW64 \
  vfsgnjx.vf_LMUL2SEW32 \
  vfsgnjx.vf_LMUL2SEW64 \
  vfsgnjx.vf_LMUL4SEW32 \
  vfsgnjx.vf_LMUL4SEW64 \
  vfsgnjx.vf_LMUL8SEW32 \
  vfsgnjx.vf_LMUL8SEW64 \
  vfsgnjx.vv_LMUL1SEW32 \
  vfsgnjx.vv_LMUL1SEW64 \
  vfsgnjx.vv_LMUL2SEW32 \
  vfsgnjx.vv_LMUL2SEW64 \
  vfsgnjx.vv_LMUL4SEW32 \
  vfsgnjx.vv_LMUL4SEW64 \
  vfsgnjx.vv_LMUL8SEW32 \
  vfsgnjx.vv_LMUL8SEW64 \
  vfsub.vf_LMUL1SEW32 \
  vfsub.vf_LMUL1SEW64 \
  vfsub.vf_LMUL2SEW32 \
  vfsub.vf_LMUL2SEW64 \
  vfsub.vf_LMUL4SEW32 \
  vfsub.vf_LMUL4SEW64 \
  vfsub.vf_LMUL8SEW32 \
  vfsub.vf_LMUL8SEW64 \
  vfsub.vv_LMUL1SEW32 \
  vfsub.vv_LMUL1SEW64 \
  vfsub.vv_LMUL2SEW32 \
  vfsub.vv_LMUL2SEW64 \
  vfsub.vv_LMUL4SEW32 \
  vfsub.vv_LMUL4SEW64 \
  vfsub.vv_LMUL8SEW32 \
  vfsub.vv_LMUL8SEW64 \
  vl1re16.v \
  vl1re32.v \
  vl1re64.v \
  vl1re8.v \
  vl2re16.v \
  vl2re32.v \
  vl2re64.v \
  vl2re8.v \
  vl4re16.v \
  vl4re32.v \
  vl4re64.v \
  vl4re8.v \
  vl8re16.v \
  vl8re32.v \
  vl8re64.v \
  vl8re8.v \
  vle16.v_LMUL1 \
  vle16.v_LMUL2 \
  vle16.v_LMUL4 \
  vle16.v_LMUL8 \
  vle32.v_LMUL1 \
  vle32.v_LMUL2 \
  vle32.v_LMUL4 \
  vle32.v_LMUL8 \
  vle64.v_LMUL1 \
  vle64.v_LMUL2 \
  vle64.v_LMUL4 \
  vle64.v_LMUL8 \
  vle8.v_LMUL1 \
  vle8.v_LMUL2 \
  vle8.v_LMUL4 \
  vle8.v_LMUL8 \
  vlse16.v_LMUL1 \
  vlse16.v_LMUL2 \
  vlse16.v_LMUL4 \
  vlse16.v_LMUL8 \
  vlse32.v_LMUL1 \
  vlse32.v_LMUL2 \
  vlse32.v_LMUL4 \
  vlse32.v_LMUL8 \
  vlse64.v_LMUL1 \
  vlse64.v_LMUL2 \
  vlse64.v_LMUL4 \
  vlse64.v_LMUL8 \
  vlse8.v_LMUL1 \
  vlse8.v_LMUL2 \
  vlse8.v_LMUL4 \
  vlse8.v_LMUL8 \
  vmax.vv_LMUL1SEW16 \
  vmax.vv_LMUL1SEW32 \
  vmax.vv_LMUL1SEW64 \
  vmax.vv_LMUL1SEW8 \
  vmax.vv_LMUL2SEW16 \
  vmax.vv_LMUL2SEW32 \
  vmax.vv_LMUL2SEW64 \
  vmax.vv_LMUL2SEW8 \
  vmax.vv_LMUL4SEW16 \
  vmax.vv_LMUL4SEW32 \
  vmax.vv_LMUL4SEW64 \
  vmax.vv_LMUL4SEW8 \
  vmax.vv_LMUL8SEW16 \
  vmax.vv_LMUL8SEW32 \
  vmax.vv_LMUL8SEW64 \
  vmax.vv_LMUL8SEW8 \
  vmax.vx_LMUL1SEW16 \
  vmax.vx_LMUL1SEW32 \
  vmax.vx_LMUL1SEW64 \
  vmax.vx_LMUL1SEW8 \
  vmax.vx_LMUL2SEW16 \
  vmax.vx_LMUL2SEW32 \
  vmax.vx_LMUL2SEW64 \
  vmax.vx_LMUL2SEW8 \
  vmax.vx_LMUL4SEW16 \
  vmax.vx_LMUL4SEW32 \
  vmax.vx_LMUL4SEW64 \
  vmax.vx_LMUL4SEW8 \
  vmax.vx_LMUL8SEW16 \
  vmax.vx_LMUL8SEW32 \
  vmax.vx_LMUL8SEW64 \
  vmax.vx_LMUL8SEW8 \
  vmaxu.vv_LMUL1SEW16 \
  vmaxu.vv_LMUL1SEW32 \
  vmaxu.vv_LMUL1SEW64 \
  vmaxu.vv_LMUL1SEW8 \
  vmaxu.vv_LMUL2SEW16 \
  vmaxu.vv_LMUL2SEW32 \
  vmaxu.vv_LMUL2SEW64 \
  vmaxu.vv_LMUL2SEW8 \
  vmaxu.vv_LMUL4SEW16 \
  vmaxu.vv_LMUL4SEW32 \
  vmaxu.vv_LMUL4SEW64 \
  vmaxu.vv_LMUL4SEW8 \
  vmaxu.vv_LMUL8SEW16 \
  vmaxu.vv_LMUL8SEW32 \
  vmaxu.vv_LMUL8SEW64 \
  vmaxu.vv_LMUL8SEW8 \
  vmaxu.vx_LMUL1SEW16 \
  vmaxu.vx_LMUL1SEW32 \
  vmaxu.vx_LMUL1SEW64 \
  vmaxu.vx_LMUL1SEW8 \
  vmaxu.vx_LMUL2SEW16 \
  vmaxu.vx_LMUL2SEW32 \
  vmaxu.vx_LMUL2SEW64 \
  vmaxu.vx_LMUL2SEW8 \
  vmaxu.vx_LMUL4SEW16 \
  vmaxu.vx_LMUL4SEW32 \
  vmaxu.vx_LMUL4SEW64 \
  vmaxu.vx_LMUL4SEW8 \
  vmaxu.vx_LMUL8SEW16 \
  vmaxu.vx_LMUL8SEW32 \
  vmaxu.vx_LMUL8SEW64 \
  vmaxu.vx_LMUL8SEW8 \
  vmerge.vim_LMUL1SEW16 \
  vmerge.vim_LMUL1SEW32 \
  vmerge.vim_LMUL1SEW64 \
  vmerge.vim_LMUL1SEW8 \
  vmerge.vim_LMUL2SEW16 \
  vmerge.vim_LMUL2SEW32 \
  vmerge.vim_LMUL2SEW64 \
  vmerge.vim_LMUL2SEW8 \
  vmerge.vim_LMUL4SEW16 \
  vmerge.vim_LMUL4SEW32 \
  vmerge.vim_LMUL4SEW64 \
  vmerge.vim_LMUL4SEW8 \
  vmerge.vim_LMUL8SEW16 \
  vmerge.vim_LMUL8SEW32 \
  vmerge.vim_LMUL8SEW64 \
  vmerge.vim_LMUL8SEW8 \
  vmerge.vvm_LMUL1SEW16 \
  vmerge.vvm_LMUL1SEW32 \
  vmerge.vvm_LMUL1SEW64 \
  vmerge.vvm_LMUL1SEW8 \
  vmerge.vvm_LMUL2SEW16 \
  vmerge.vvm_LMUL2SEW32 \
  vmerge.vvm_LMUL2SEW64 \
  vmerge.vvm_LMUL2SEW8 \
  vmerge.vvm_LMUL4SEW16 \
  vmerge.vvm_LMUL4SEW32 \
  vmerge.vvm_LMUL4SEW64 \
  vmerge.vvm_LMUL4SEW8 \
  vmerge.vvm_LMUL8SEW16 \
  vmerge.vvm_LMUL8SEW32 \
  vmerge.vvm_LMUL8SEW64 \
  vmerge.vvm_LMUL8SEW8 \
  vmerge.vxm_LMUL1SEW16 \
  vmerge.vxm_LMUL1SEW32 \
  vmerge.vxm_LMUL1SEW64 \
  vmerge.vxm_LMUL1SEW8 \
  vmerge.vxm_LMUL2SEW16 \
  vmerge.vxm_LMUL2SEW32 \
  vmerge.vxm_LMUL2SEW64 \
  vmerge.vxm_LMUL2SEW8 \
  vmerge.vxm_LMUL4SEW16 \
  vmerge.vxm_LMUL4SEW32 \
  vmerge.vxm_LMUL4SEW64 \
  vmerge.vxm_LMUL4SEW8 \
  vmerge.vxm_LMUL8SEW16 \
  vmerge.vxm_LMUL8SEW32 \
  vmerge.vxm_LMUL8SEW64 \
  vmerge.vxm_LMUL8SEW8 \
  vmin.vv_LMUL1SEW16 \
  vmin.vv_LMUL1SEW32 \
  vmin.vv_LMUL1SEW64 \
  vmin.vv_LMUL1SEW8 \
  vmin.vv_LMUL2SEW16 \
  vmin.vv_LMUL2SEW32 \
  vmin.vv_LMUL2SEW64 \
  vmin.vv_LMUL2SEW8 \
  vmin.vv_LMUL4SEW16 \
  vmin.vv_LMUL4SEW32 \
  vmin.vv_LMUL4SEW64 \
  vmin.vv_LMUL4SEW8 \
  vmin.vv_LMUL8SEW16 \
  vmin.vv_LMUL8SEW32 \
  vmin.vv_LMUL8SEW64 \
  vmin.vv_LMUL8SEW8 \
  vmin.vx_LMUL1SEW16 \
  vmin.vx_LMUL1SEW32 \
  vmin.vx_LMUL1SEW64 \
  vmin.vx_LMUL1SEW8 \
  vmin.vx_LMUL2SEW16 \
  vmin.vx_LMUL2SEW32 \
  vmin.vx_LMUL2SEW64 \
  vmin.vx_LMUL2SEW8 \
  vmin.vx_LMUL4SEW16 \
  vmin.vx_LMUL4SEW32 \
  vmin.vx_LMUL4SEW64 \
  vmin.vx_LMUL4SEW8 \
  vmin.vx_LMUL8SEW16 \
  vmin.vx_LMUL8SEW32 \
  vmin.vx_LMUL8SEW64 \
  vmin.vx_LMUL8SEW8 \
  vminu.vv_LMUL1SEW16 \
  vminu.vv_LMUL1SEW32 \
  vminu.vv_LMUL1SEW64 \
  vminu.vv_LMUL1SEW8 \
  vminu.vv_LMUL2SEW16 \
  vminu.vv_LMUL2SEW32 \
  vminu.vv_LMUL2SEW64 \
  vminu.vv_LMUL2SEW8 \
  vminu.vv_LMUL4SEW16 \
  vminu.vv_LMUL4SEW32 \
  vminu.vv_LMUL4SEW64 \
  vminu.vv_LMUL4SEW8 \
  vminu.vv_LMUL8SEW16 \
  vminu.vv_LMUL8SEW32 \
  vminu.vv_LMUL8SEW64 \
  vminu.vv_LMUL8SEW8 \
  vminu.vx_LMUL1SEW16 \
  vminu.vx_LMUL1SEW32 \
  vminu.vx_LMUL1SEW64 \
  vminu.vx_LMUL1SEW8 \
  vminu.vx_LMUL2SEW16 \
  vminu.vx_LMUL2SEW32 \
  vminu.vx_LMUL2SEW64 \
  vminu.vx_LMUL2SEW8 \
  vminu.vx_LMUL4SEW16 \
  vminu.vx_LMUL4SEW32 \
  vminu.vx_LMUL4SEW64 \
  vminu.vx_LMUL4SEW8 \
  vminu.vx_LMUL8SEW16 \
  vminu.vx_LMUL8SEW32 \
  vminu.vx_LMUL8SEW64 \
  vminu.vx_LMUL8SEW8 \
  vmul.vv_LMUL1SEW16 \
  vmul.vv_LMUL1SEW32 \
  vmul.vv_LMUL1SEW64 \
  vmul.vv_LMUL1SEW8 \
  vmul.vv_LMUL2SEW16 \
  vmul.vv_LMUL2SEW32 \
  vmul.vv_LMUL2SEW64 \
  vmul.vv_LMUL2SEW8 \
  vmul.vv_LMUL4SEW16 \
  vmul.vv_LMUL4SEW32 \
  vmul.vv_LMUL4SEW64 \
  vmul.vv_LMUL4SEW8 \
  vmul.vv_LMUL8SEW16 \
  vmul.vv_LMUL8SEW32 \
  vmul.vv_LMUL8SEW64 \
  vmul.vv_LMUL8SEW8 \
  vmul.vx_LMUL1SEW16 \
  vmul.vx_LMUL1SEW32 \
  vmul.vx_LMUL1SEW64 \
  vmul.vx_LMUL1SEW8 \
  vmul.vx_LMUL2SEW16 \
  vmul.vx_LMUL2SEW32 \
  vmul.vx_LMUL2SEW64 \
  vmul.vx_LMUL2SEW8 \
  vmul.vx_LMUL4SEW16 \
  vmul.vx_LMUL4SEW32 \
  vmul.vx_LMUL4SEW64 \
  vmul.vx_LMUL4SEW8 \
  vmul.vx_LMUL8SEW16 \
  vmul.vx_LMUL8SEW32 \
  vmul.vx_LMUL8SEW64 \
  vmul.vx_LMUL8SEW8 \
  vmulh.vv_LMUL1SEW16 \
  vmulh.vv_LMUL1SEW32 \
  vmulh.vv_LMUL1SEW64 \
  vmulh.vv_LMUL1SEW8 \
  vmulh.vv_LMUL2SEW16 \
  vmulh.vv_LMUL2SEW32 \
  vmulh.vv_LMUL2SEW64 \
  vmulh.vv_LMUL2SEW8 \
  vmulh.vv_LMUL4SEW16 \
  vmulh.vv_LMUL4SEW32 \
  vmulh.vv_LMUL4SEW64 \
  vmulh.vv_LMUL4SEW8 \
  vmulh.vv_LMUL8SEW16 \
  vmulh.vv_LMUL8SEW32 \
  vmulh.vv_LMUL8SEW64 \
  vmulh.vv_LMUL8SEW8 \
  vmulh.vx_LMUL1SEW16 \
  vmulh.vx_LMUL1SEW32 \
  vmulh.vx_LMUL1SEW64 \
  vmulh.vx_LMUL1SEW8 \
  vmulh.vx_LMUL2SEW16 \
  vmulh.vx_LMUL2SEW32 \
  vmulh.vx_LMUL2SEW64 \
  vmulh.vx_LMUL2SEW8 \
  vmulh.vx_LMUL4SEW16 \
  vmulh.vx_LMUL4SEW32 \
  vmulh.vx_LMUL4SEW64 \
  vmulh.vx_LMUL4SEW8 \
  vmulh.vx_LMUL8SEW16 \
  vmulh.vx_LMUL8SEW32 \
  vmulh.vx_LMUL8SEW64 \
  vmulh.vx_LMUL8SEW8 \
  vmulhsu.vv_LMUL1SEW16 \
  vmulhsu.vv_LMUL1SEW32 \
  vmulhsu.vv_LMUL1SEW64 \
  vmulhsu.vv_LMUL1SEW8 \
  vmulhsu.vv_LMUL2SEW16 \
  vmulhsu.vv_LMUL2SEW32 \
  vmulhsu.vv_LMUL2SEW64 \
  vmulhsu.vv_LMUL2SEW8 \
  vmulhsu.vv_LMUL4SEW16 \
  vmulhsu.vv_LMUL4SEW32 \
  vmulhsu.vv_LMUL4SEW64 \
  vmulhsu.vv_LMUL4SEW8 \
  vmulhsu.vv_LMUL8SEW16 \
  vmulhsu.vv_LMUL8SEW32 \
  vmulhsu.vv_LMUL8SEW64 \
  vmulhsu.vv_LMUL8SEW8 \
  vmulhsu.vx_LMUL1SEW16 \
  vmulhsu.vx_LMUL1SEW32 \
  vmulhsu.vx_LMUL1SEW64 \
  vmulhsu.vx_LMUL1SEW8 \
  vmulhsu.vx_LMUL2SEW16 \
  vmulhsu.vx_LMUL2SEW32 \
  vmulhsu.vx_LMUL2SEW64 \
  vmulhsu.vx_LMUL2SEW8 \
  vmulhsu.vx_LMUL4SEW16 \
  vmulhsu.vx_LMUL4SEW32 \
  vmulhsu.vx_LMUL4SEW64 \
  vmulhsu.vx_LMUL4SEW8 \
  vmulhsu.vx_LMUL8SEW16 \
  vmulhsu.vx_LMUL8SEW32 \
  vmulhsu.vx_LMUL8SEW64 \
  vmulhsu.vx_LMUL8SEW8 \
  vmulhu.vv_LMUL1SEW16 \
  vmulhu.vv_LMUL1SEW32 \
  vmulhu.vv_LMUL1SEW64 \
  vmulhu.vv_LMUL1SEW8 \
  vmulhu.vv_LMUL2SEW16 \
  vmulhu.vv_LMUL2SEW32 \
  vmulhu.vv_LMUL2SEW64 \
  vmulhu.vv_LMUL2SEW8 \
  vmulhu.vv_LMUL4SEW16 \
  vmulhu.vv_LMUL4SEW32 \
  vmulhu.vv_LMUL4SEW64 \
  vmulhu.vv_LMUL4SEW8 \
  vmulhu.vv_LMUL8SEW16 \
  vmulhu.vv_LMUL8SEW32 \
  vmulhu.vv_LMUL8SEW64 \
  vmulhu.vv_LMUL8SEW8 \
  vmulhu.vx_LMUL1SEW16 \
  vmulhu.vx_LMUL1SEW32 \
  vmulhu.vx_LMUL1SEW64 \
  vmulhu.vx_LMUL1SEW8 \
  vmulhu.vx_LMUL2SEW16 \
  vmulhu.vx_LMUL2SEW32 \
  vmulhu.vx_LMUL2SEW64 \
  vmulhu.vx_LMUL2SEW8 \
  vmulhu.vx_LMUL4SEW16 \
  vmulhu.vx_LMUL4SEW32 \
  vmulhu.vx_LMUL4SEW64 \
  vmulhu.vx_LMUL4SEW8 \
  vmulhu.vx_LMUL8SEW16 \
  vmulhu.vx_LMUL8SEW32 \
  vmulhu.vx_LMUL8SEW64 \
  vmulhu.vx_LMUL8SEW8 \
  vor.vi_LMUL1SEW16 \
  vor.vi_LMUL1SEW32 \
  vor.vi_LMUL1SEW64 \
  vor.vi_LMUL1SEW8 \
  vor.vi_LMUL2SEW16 \
  vor.vi_LMUL2SEW32 \
  vor.vi_LMUL2SEW64 \
  vor.vi_LMUL2SEW8 \
  vor.vi_LMUL4SEW16 \
  vor.vi_LMUL4SEW32 \
  vor.vi_LMUL4SEW64 \
  vor.vi_LMUL4SEW8 \
  vor.vi_LMUL8SEW16 \
  vor.vi_LMUL8SEW32 \
  vor.vi_LMUL8SEW64 \
  vor.vi_LMUL8SEW8 \
  vor.vv_LMUL1SEW16 \
  vor.vv_LMUL1SEW32 \
  vor.vv_LMUL1SEW64 \
  vor.vv_LMUL1SEW8 \
  vor.vv_LMUL2SEW16 \
  vor.vv_LMUL2SEW32 \
  vor.vv_LMUL2SEW64 \
  vor.vv_LMUL2SEW8 \
  vor.vv_LMUL4SEW16 \
  vor.vv_LMUL4SEW32 \
  vor.vv_LMUL4SEW64 \
  vor.vv_LMUL4SEW8 \
  vor.vv_LMUL8SEW16 \
  vor.vv_LMUL8SEW32 \
  vor.vv_LMUL8SEW64 \
  vor.vv_LMUL8SEW8 \
  vor.vx_LMUL1SEW16 \
  vor.vx_LMUL1SEW32 \
  vor.vx_LMUL1SEW64 \
  vor.vx_LMUL1SEW8 \
  vor.vx_LMUL2SEW16 \
  vor.vx_LMUL2SEW32 \
  vor.vx_LMUL2SEW64 \
  vor.vx_LMUL2SEW8 \
  vor.vx_LMUL4SEW16 \
  vor.vx_LMUL4SEW32 \
  vor.vx_LMUL4SEW64 \
  vor.vx_LMUL4SEW8 \
  vor.vx_LMUL8SEW16 \
  vor.vx_LMUL8SEW32 \
  vor.vx_LMUL8SEW64 \
  vor.vx_LMUL8SEW8 \
  vrem.vv_LMUL1SEW16 \
  vrem.vv_LMUL1SEW32 \
  vrem.vv_LMUL1SEW64 \
  vrem.vv_LMUL1SEW8 \
  vrem.vv_LMUL2SEW16 \
  vrem.vv_LMUL2SEW32 \
  vrem.vv_LMUL2SEW64 \
  vrem.vv_LMUL2SEW8 \
  vrem.vv_LMUL4SEW16 \
  vrem.vv_LMUL4SEW32 \
  vrem.vv_LMUL4SEW64 \
  vrem.vv_LMUL4SEW8 \
  vrem.vv_LMUL8SEW16 \
  vrem.vv_LMUL8SEW32 \
  vrem.vv_LMUL8SEW64 \
  vrem.vv_LMUL8SEW8 \
  vrem.vx_LMUL1SEW16 \
  vrem.vx_LMUL1SEW32 \
  vrem.vx_LMUL1SEW64 \
  vrem.vx_LMUL1SEW8 \
  vrem.vx_LMUL2SEW16 \
  vrem.vx_LMUL2SEW32 \
  vrem.vx_LMUL2SEW64 \
  vrem.vx_LMUL2SEW8 \
  vrem.vx_LMUL4SEW16 \
  vrem.vx_LMUL4SEW32 \
  vrem.vx_LMUL4SEW64 \
  vrem.vx_LMUL4SEW8 \
  vrem.vx_LMUL8SEW16 \
  vrem.vx_LMUL8SEW32 \
  vrem.vx_LMUL8SEW64 \
  vrem.vx_LMUL8SEW8 \
  vremu.vv_LMUL1SEW16 \
  vremu.vv_LMUL1SEW32 \
  vremu.vv_LMUL1SEW64 \
  vremu.vv_LMUL1SEW8 \
  vremu.vv_LMUL2SEW16 \
  vremu.vv_LMUL2SEW32 \
  vremu.vv_LMUL2SEW64 \
  vremu.vv_LMUL2SEW8 \
  vremu.vv_LMUL4SEW16 \
  vremu.vv_LMUL4SEW32 \
  vremu.vv_LMUL4SEW64 \
  vremu.vv_LMUL4SEW8 \
  vremu.vv_LMUL8SEW16 \
  vremu.vv_LMUL8SEW32 \
  vremu.vv_LMUL8SEW64 \
  vremu.vv_LMUL8SEW8 \
  vremu.vx_LMUL1SEW16 \
  vremu.vx_LMUL1SEW32 \
  vremu.vx_LMUL1SEW64 \
  vremu.vx_LMUL1SEW8 \
  vremu.vx_LMUL2SEW16 \
  vremu.vx_LMUL2SEW32 \
  vremu.vx_LMUL2SEW64 \
  vremu.vx_LMUL2SEW8 \
  vremu.vx_LMUL4SEW16 \
  vremu.vx_LMUL4SEW32 \
  vremu.vx_LMUL4SEW64 \
  vremu.vx_LMUL4SEW8 \
  vremu.vx_LMUL8SEW16 \
  vremu.vx_LMUL8SEW32 \
  vremu.vx_LMUL8SEW64 \
  vremu.vx_LMUL8SEW8 \
  vrgather.vi_LMUL1SEW16 \
  vrgather.vi_LMUL1SEW32 \
  vrgather.vi_LMUL1SEW64 \
  vrgather.vi_LMUL1SEW8 \
  vrgather.vi_LMUL2SEW16 \
  vrgather.vi_LMUL2SEW32 \
  vrgather.vi_LMUL2SEW64 \
  vrgather.vi_LMUL2SEW8 \
  vrgather.vi_LMUL4SEW16 \
  vrgather.vi_LMUL4SEW32 \
  vrgather.vi_LMUL4SEW64 \
  vrgather.vi_LMUL4SEW8 \
  vrgather.vi_LMUL8SEW16 \
  vrgather.vi_LMUL8SEW32 \
  vrgather.vi_LMUL8SEW64 \
  vrgather.vi_LMUL8SEW8 \
  vrgather.vv_LMUL1SEW16 \
  vrgather.vv_LMUL1SEW32 \
  vrgather.vv_LMUL1SEW64 \
  vrgather.vv_LMUL1SEW8 \
  vrgather.vv_LMUL2SEW16 \
  vrgather.vv_LMUL2SEW32 \
  vrgather.vv_LMUL2SEW64 \
  vrgather.vv_LMUL2SEW8 \
  vrgather.vv_LMUL4SEW16 \
  vrgather.vv_LMUL4SEW32 \
  vrgather.vv_LMUL4SEW64 \
  vrgather.vv_LMUL4SEW8 \
  vrgather.vv_LMUL8SEW16 \
  vrgather.vv_LMUL8SEW32 \
  vrgather.vv_LMUL8SEW64 \
  vrgather.vv_LMUL8SEW8 \
  vrgather.vx_LMUL1SEW16 \
  vrgather.vx_LMUL1SEW32 \
  vrgather.vx_LMUL1SEW64 \
  vrgather.vx_LMUL1SEW8 \
  vrgather.vx_LMUL2SEW16 \
  vrgather.vx_LMUL2SEW32 \
  vrgather.vx_LMUL2SEW64 \
  vrgather.vx_LMUL2SEW8 \
  vrgather.vx_LMUL4SEW16 \
  vrgather.vx_LMUL4SEW32 \
  vrgather.vx_LMUL4SEW64 \
  vrgather.vx_LMUL4SEW8 \
  vrgather.vx_LMUL8SEW16 \
  vrgather.vx_LMUL8SEW32 \
  vrgather.vx_LMUL8SEW64 \
  vrgather.vx_LMUL8SEW8 \
  vrsub.vi_LMUL1SEW16 \
  vrsub.vi_LMUL1SEW32 \
  vrsub.vi_LMUL1SEW64 \
  vrsub.vi_LMUL1SEW8 \
  vrsub.vi_LMUL2SEW16 \
  vrsub.vi_LMUL2SEW32 \
  vrsub.vi_LMUL2SEW64 \
  vrsub.vi_LMUL2SEW8 \
  vrsub.vi_LMUL4SEW16 \
  vrsub.vi_LMUL4SEW32 \
  vrsub.vi_LMUL4SEW64 \
  vrsub.vi_LMUL4SEW8 \
  vrsub.vi_LMUL8SEW16 \
  vrsub.vi_LMUL8SEW32 \
  vrsub.vi_LMUL8SEW64 \
  vrsub.vi_LMUL8SEW8 \
  vrsub.vx_LMUL1SEW16 \
  vrsub.vx_LMUL1SEW32 \
  vrsub.vx_LMUL1SEW64 \
  vrsub.vx_LMUL1SEW8 \
  vrsub.vx_LMUL2SEW16 \
  vrsub.vx_LMUL2SEW32 \
  vrsub.vx_LMUL2SEW64 \
  vrsub.vx_LMUL2SEW8 \
  vrsub.vx_LMUL4SEW16 \
  vrsub.vx_LMUL4SEW32 \
  vrsub.vx_LMUL4SEW64 \
  vrsub.vx_LMUL4SEW8 \
  vrsub.vx_LMUL8SEW16 \
  vrsub.vx_LMUL8SEW32 \
  vrsub.vx_LMUL8SEW64 \
  vrsub.vx_LMUL8SEW8 \
  vs1r.v \
  vs2r.v \
  vs4r.v \
  vs8r.v \
  vsaddu.vi_LMUL1SEW16 \
  vsaddu.vi_LMUL1SEW32 \
  vsaddu.vi_LMUL1SEW64 \
  vsaddu.vi_LMUL1SEW8 \
  vsaddu.vi_LMUL2SEW16 \
  vsaddu.vi_LMUL2SEW32 \
  vsaddu.vi_LMUL2SEW64 \
  vsaddu.vi_LMUL2SEW8 \
  vsaddu.vi_LMUL4SEW16 \
  vsaddu.vi_LMUL4SEW32 \
  vsaddu.vi_LMUL4SEW64 \
  vsaddu.vi_LMUL4SEW8 \
  vsaddu.vi_LMUL8SEW16 \
  vsaddu.vi_LMUL8SEW32 \
  vsaddu.vi_LMUL8SEW64 \
  vsaddu.vi_LMUL8SEW8 \
  vsaddu.vv_LMUL1SEW16 \
  vsaddu.vv_LMUL1SEW32 \
  vsaddu.vv_LMUL1SEW64 \
  vsaddu.vv_LMUL1SEW8 \
  vsaddu.vv_LMUL2SEW16 \
  vsaddu.vv_LMUL2SEW32 \
  vsaddu.vv_LMUL2SEW64 \
  vsaddu.vv_LMUL2SEW8 \
  vsaddu.vv_LMUL4SEW16 \
  vsaddu.vv_LMUL4SEW32 \
  vsaddu.vv_LMUL4SEW64 \
  vsaddu.vv_LMUL4SEW8 \
  vsaddu.vv_LMUL8SEW16 \
  vsaddu.vv_LMUL8SEW32 \
  vsaddu.vv_LMUL8SEW64 \
  vsaddu.vv_LMUL8SEW8 \
  vsaddu.vx_LMUL1SEW16 \
  vsaddu.vx_LMUL1SEW32 \
  vsaddu.vx_LMUL1SEW64 \
  vsaddu.vx_LMUL1SEW8 \
  vsaddu.vx_LMUL2SEW16 \
  vsaddu.vx_LMUL2SEW32 \
  vsaddu.vx_LMUL2SEW64 \
  vsaddu.vx_LMUL2SEW8 \
  vsaddu.vx_LMUL4SEW16 \
  vsaddu.vx_LMUL4SEW32 \
  vsaddu.vx_LMUL4SEW64 \
  vsaddu.vx_LMUL4SEW8 \
  vsaddu.vx_LMUL8SEW16 \
  vsaddu.vx_LMUL8SEW32 \
  vsaddu.vx_LMUL8SEW64 \
  vsaddu.vx_LMUL8SEW8 \
  vsbc.vvm_LMUL1SEW16 \
  vsbc.vvm_LMUL1SEW32 \
  vsbc.vvm_LMUL1SEW64 \
  vsbc.vvm_LMUL1SEW8 \
  vsbc.vvm_LMUL2SEW16 \
  vsbc.vvm_LMUL2SEW32 \
  vsbc.vvm_LMUL2SEW64 \
  vsbc.vvm_LMUL2SEW8 \
  vsbc.vvm_LMUL4SEW16 \
  vsbc.vvm_LMUL4SEW32 \
  vsbc.vvm_LMUL4SEW64 \
  vsbc.vvm_LMUL4SEW8 \
  vsbc.vvm_LMUL8SEW16 \
  vsbc.vvm_LMUL8SEW32 \
  vsbc.vvm_LMUL8SEW64 \
  vsbc.vvm_LMUL8SEW8 \
  vsbc.vxm_LMUL1SEW16 \
  vsbc.vxm_LMUL1SEW32 \
  vsbc.vxm_LMUL1SEW64 \
  vsbc.vxm_LMUL1SEW8 \
  vsbc.vxm_LMUL2SEW16 \
  vsbc.vxm_LMUL2SEW32 \
  vsbc.vxm_LMUL2SEW64 \
  vsbc.vxm_LMUL2SEW8 \
  vsbc.vxm_LMUL4SEW16 \
  vsbc.vxm_LMUL4SEW32 \
  vsbc.vxm_LMUL4SEW64 \
  vsbc.vxm_LMUL4SEW8 \
  vsbc.vxm_LMUL8SEW16 \
  vsbc.vxm_LMUL8SEW32 \
  vsbc.vxm_LMUL8SEW64 \
  vsbc.vxm_LMUL8SEW8 \
  vse16.v_LMUL1 \
  vse16.v_LMUL2 \
  vse16.v_LMUL4 \
  vse16.v_LMUL8 \
  vse32.v_LMUL1 \
  vse32.v_LMUL2 \
  vse32.v_LMUL4 \
  vse32.v_LMUL8 \
  vse64.v_LMUL1 \
  vse64.v_LMUL2 \
  vse64.v_LMUL4 \
  vse64.v_LMUL8 \
  vse8.v_LMUL1 \
  vse8.v_LMUL2 \
  vse8.v_LMUL4 \
  vse8.v_LMUL8 \
  vslidedown.vi_LMUL1SEW16 \
  vslidedown.vi_LMUL1SEW32 \
  vslidedown.vi_LMUL1SEW64 \
  vslidedown.vi_LMUL1SEW8 \
  vslidedown.vi_LMUL2SEW16 \
  vslidedown.vi_LMUL2SEW32 \
  vslidedown.vi_LMUL2SEW64 \
  vslidedown.vi_LMUL2SEW8 \
  vslidedown.vi_LMUL4SEW16 \
  vslidedown.vi_LMUL4SEW32 \
  vslidedown.vi_LMUL4SEW64 \
  vslidedown.vi_LMUL4SEW8 \
  vslidedown.vi_LMUL8SEW16 \
  vslidedown.vi_LMUL8SEW32 \
  vslidedown.vi_LMUL8SEW64 \
  vslidedown.vi_LMUL8SEW8 \
  vslidedown.vx_LMUL1SEW16 \
  vslidedown.vx_LMUL1SEW32 \
  vslidedown.vx_LMUL1SEW64 \
  vslidedown.vx_LMUL1SEW8 \
  vslidedown.vx_LMUL2SEW16 \
  vslidedown.vx_LMUL2SEW32 \
  vslidedown.vx_LMUL2SEW64 \
  vslidedown.vx_LMUL2SEW8 \
  vslidedown.vx_LMUL4SEW16 \
  vslidedown.vx_LMUL4SEW32 \
  vslidedown.vx_LMUL4SEW64 \
  vslidedown.vx_LMUL4SEW8 \
  vslidedown.vx_LMUL8SEW16 \
  vslidedown.vx_LMUL8SEW32 \
  vslidedown.vx_LMUL8SEW64 \
  vslidedown.vx_LMUL8SEW8 \
  vslideup.vi_LMUL1SEW16 \
  vslideup.vi_LMUL1SEW32 \
  vslideup.vi_LMUL1SEW64 \
  vslideup.vi_LMUL1SEW8 \
  vslideup.vi_LMUL2SEW16 \
  vslideup.vi_LMUL2SEW32 \
  vslideup.vi_LMUL2SEW64 \
  vslideup.vi_LMUL2SEW8 \
  vslideup.vi_LMUL4SEW16 \
  vslideup.vi_LMUL4SEW32 \
  vslideup.vi_LMUL4SEW64 \
  vslideup.vi_LMUL4SEW8 \
  vslideup.vi_LMUL8SEW16 \
  vslideup.vi_LMUL8SEW32 \
  vslideup.vi_LMUL8SEW64 \
  vslideup.vi_LMUL8SEW8 \
  vslideup.vx_LMUL1SEW16 \
  vslideup.vx_LMUL1SEW32 \
  vslideup.vx_LMUL1SEW64 \
  vslideup.vx_LMUL1SEW8 \
  vslideup.vx_LMUL2SEW16 \
  vslideup.vx_LMUL2SEW32 \
  vslideup.vx_LMUL2SEW64 \
  vslideup.vx_LMUL2SEW8 \
  vslideup.vx_LMUL4SEW16 \
  vslideup.vx_LMUL4SEW32 \
  vslideup.vx_LMUL4SEW64 \
  vslideup.vx_LMUL4SEW8 \
  vslideup.vx_LMUL8SEW16 \
  vslideup.vx_LMUL8SEW32 \
  vslideup.vx_LMUL8SEW64 \
  vslideup.vx_LMUL8SEW8 \
  vsll.vi_LMUL1SEW16 \
  vsll.vi_LMUL1SEW32 \
  vsll.vi_LMUL1SEW64 \
  vsll.vi_LMUL1SEW8 \
  vsll.vi_LMUL2SEW16 \
  vsll.vi_LMUL2SEW32 \
  vsll.vi_LMUL2SEW64 \
  vsll.vi_LMUL2SEW8 \
  vsll.vi_LMUL4SEW16 \
  vsll.vi_LMUL4SEW32 \
  vsll.vi_LMUL4SEW64 \
  vsll.vi_LMUL4SEW8 \
  vsll.vi_LMUL8SEW16 \
  vsll.vi_LMUL8SEW32 \
  vsll.vi_LMUL8SEW64 \
  vsll.vi_LMUL8SEW8 \
  vsll.vv_LMUL1SEW16 \
  vsll.vv_LMUL1SEW32 \
  vsll.vv_LMUL1SEW64 \
  vsll.vv_LMUL1SEW8 \
  vsll.vv_LMUL2SEW16 \
  vsll.vv_LMUL2SEW32 \
  vsll.vv_LMUL2SEW64 \
  vsll.vv_LMUL2SEW8 \
  vsll.vv_LMUL4SEW16 \
  vsll.vv_LMUL4SEW32 \
  vsll.vv_LMUL4SEW64 \
  vsll.vv_LMUL4SEW8 \
  vsll.vv_LMUL8SEW16 \
  vsll.vv_LMUL8SEW32 \
  vsll.vv_LMUL8SEW64 \
  vsll.vv_LMUL8SEW8 \
  vsll.vx_LMUL1SEW16 \
  vsll.vx_LMUL1SEW32 \
  vsll.vx_LMUL1SEW64 \
  vsll.vx_LMUL1SEW8 \
  vsll.vx_LMUL2SEW16 \
  vsll.vx_LMUL2SEW32 \
  vsll.vx_LMUL2SEW64 \
  vsll.vx_LMUL2SEW8 \
  vsll.vx_LMUL4SEW16 \
  vsll.vx_LMUL4SEW32 \
  vsll.vx_LMUL4SEW64 \
  vsll.vx_LMUL4SEW8 \
  vsll.vx_LMUL8SEW16 \
  vsll.vx_LMUL8SEW32 \
  vsll.vx_LMUL8SEW64 \
  vsll.vx_LMUL8SEW8 \
  vsra.vi_LMUL1SEW16 \
  vsra.vi_LMUL1SEW32 \
  vsra.vi_LMUL1SEW64 \
  vsra.vi_LMUL1SEW8 \
  vsra.vi_LMUL2SEW16 \
  vsra.vi_LMUL2SEW32 \
  vsra.vi_LMUL2SEW64 \
  vsra.vi_LMUL2SEW8 \
  vsra.vi_LMUL4SEW16 \
  vsra.vi_LMUL4SEW32 \
  vsra.vi_LMUL4SEW64 \
  vsra.vi_LMUL4SEW8 \
  vsra.vi_LMUL8SEW16 \
  vsra.vi_LMUL8SEW32 \
  vsra.vi_LMUL8SEW64 \
  vsra.vi_LMUL8SEW8 \
  vsra.vv_LMUL1SEW16 \
  vsra.vv_LMUL1SEW32 \
  vsra.vv_LMUL1SEW64 \
  vsra.vv_LMUL1SEW8 \
  vsra.vv_LMUL2SEW16 \
  vsra.vv_LMUL2SEW32 \
  vsra.vv_LMUL2SEW64 \
  vsra.vv_LMUL2SEW8 \
  vsra.vv_LMUL4SEW16 \
  vsra.vv_LMUL4SEW32 \
  vsra.vv_LMUL4SEW64 \
  vsra.vv_LMUL4SEW8 \
  vsra.vv_LMUL8SEW16 \
  vsra.vv_LMUL8SEW32 \
  vsra.vv_LMUL8SEW64 \
  vsra.vv_LMUL8SEW8 \
  vsra.vx_LMUL1SEW16 \
  vsra.vx_LMUL1SEW32 \
  vsra.vx_LMUL1SEW64 \
  vsra.vx_LMUL1SEW8 \
  vsra.vx_LMUL2SEW16 \
  vsra.vx_LMUL2SEW32 \
  vsra.vx_LMUL2SEW64 \
  vsra.vx_LMUL2SEW8 \
  vsra.vx_LMUL4SEW16 \
  vsra.vx_LMUL4SEW32 \
  vsra.vx_LMUL4SEW64 \
  vsra.vx_LMUL4SEW8 \
  vsra.vx_LMUL8SEW16 \
  vsra.vx_LMUL8SEW32 \
  vsra.vx_LMUL8SEW64 \
  vsra.vx_LMUL8SEW8 \
  vsrl.vi_LMUL1SEW16 \
  vsrl.vi_LMUL1SEW32 \
  vsrl.vi_LMUL1SEW64 \
  vsrl.vi_LMUL1SEW8 \
  vsrl.vi_LMUL2SEW16 \
  vsrl.vi_LMUL2SEW32 \
  vsrl.vi_LMUL2SEW64 \
  vsrl.vi_LMUL2SEW8 \
  vsrl.vi_LMUL4SEW16 \
  vsrl.vi_LMUL4SEW32 \
  vsrl.vi_LMUL4SEW64 \
  vsrl.vi_LMUL4SEW8 \
  vsrl.vi_LMUL8SEW16 \
  vsrl.vi_LMUL8SEW32 \
  vsrl.vi_LMUL8SEW64 \
  vsrl.vi_LMUL8SEW8 \
  vsrl.vv_LMUL1SEW16 \
  vsrl.vv_LMUL1SEW32 \
  vsrl.vv_LMUL1SEW64 \
  vsrl.vv_LMUL1SEW8 \
  vsrl.vv_LMUL2SEW16 \
  vsrl.vv_LMUL2SEW32 \
  vsrl.vv_LMUL2SEW64 \
  vsrl.vv_LMUL2SEW8 \
  vsrl.vv_LMUL4SEW16 \
  vsrl.vv_LMUL4SEW32 \
  vsrl.vv_LMUL4SEW64 \
  vsrl.vv_LMUL4SEW8 \
  vsrl.vv_LMUL8SEW16 \
  vsrl.vv_LMUL8SEW32 \
  vsrl.vv_LMUL8SEW64 \
  vsrl.vv_LMUL8SEW8 \
  vsrl.vx_LMUL1SEW16 \
  vsrl.vx_LMUL1SEW32 \
  vsrl.vx_LMUL1SEW64 \
  vsrl.vx_LMUL1SEW8 \
  vsrl.vx_LMUL2SEW16 \
  vsrl.vx_LMUL2SEW32 \
  vsrl.vx_LMUL2SEW64 \
  vsrl.vx_LMUL2SEW8 \
  vsrl.vx_LMUL4SEW16 \
  vsrl.vx_LMUL4SEW32 \
  vsrl.vx_LMUL4SEW64 \
  vsrl.vx_LMUL4SEW8 \
  vsrl.vx_LMUL8SEW16 \
  vsrl.vx_LMUL8SEW32 \
  vsrl.vx_LMUL8SEW64 \
  vsrl.vx_LMUL8SEW8 \
  vsub.vv_LMUL1SEW16 \
  vsub.vv_LMUL1SEW32 \
  vsub.vv_LMUL1SEW64 \
  vsub.vv_LMUL1SEW8 \
  vsub.vv_LMUL2SEW16 \
  vsub.vv_LMUL2SEW32 \
  vsub.vv_LMUL2SEW64 \
  vsub.vv_LMUL2SEW8 \
  vsub.vv_LMUL4SEW16 \
  vsub.vv_LMUL4SEW32 \
  vsub.vv_LMUL4SEW64 \
  vsub.vv_LMUL4SEW8 \
  vsub.vv_LMUL8SEW16 \
  vsub.vv_LMUL8SEW32 \
  vsub.vv_LMUL8SEW64 \
  vsub.vv_LMUL8SEW8 \
  vsub.vx_LMUL1SEW16 \
  vsub.vx_LMUL1SEW32 \
  vsub.vx_LMUL1SEW64 \
  vsub.vx_LMUL1SEW8 \
  vsub.vx_LMUL2SEW16 \
  vsub.vx_LMUL2SEW32 \
  vsub.vx_LMUL2SEW64 \
  vsub.vx_LMUL2SEW8 \
  vsub.vx_LMUL4SEW16 \
  vsub.vx_LMUL4SEW32 \
  vsub.vx_LMUL4SEW64 \
  vsub.vx_LMUL4SEW8 \
  vsub.vx_LMUL8SEW16 \
  vsub.vx_LMUL8SEW32 \
  vsub.vx_LMUL8SEW64 \
  vsub.vx_LMUL8SEW8 \
  vxor.vi_LMUL1SEW16 \
  vxor.vi_LMUL1SEW32 \
  vxor.vi_LMUL1SEW64 \
  vxor.vi_LMUL1SEW8 \
  vxor.vi_LMUL2SEW16 \
  vxor.vi_LMUL2SEW32 \
  vxor.vi_LMUL2SEW64 \
  vxor.vi_LMUL2SEW8 \
  vxor.vi_LMUL4SEW16 \
  vxor.vi_LMUL4SEW32 \
  vxor.vi_LMUL4SEW64 \
  vxor.vi_LMUL4SEW8 \
  vxor.vi_LMUL8SEW16 \
  vxor.vi_LMUL8SEW32 \
  vxor.vi_LMUL8SEW64 \
  vxor.vi_LMUL8SEW8 \
  vxor.vv_LMUL1SEW16 \
  vxor.vv_LMUL1SEW32 \
  vxor.vv_LMUL1SEW64 \
  vxor.vv_LMUL1SEW8 \
  vxor.vv_LMUL2SEW16 \
  vxor.vv_LMUL2SEW32 \
  vxor.vv_LMUL2SEW64 \
  vxor.vv_LMUL2SEW8 \
  vxor.vv_LMUL4SEW16 \
  vxor.vv_LMUL4SEW32 \
  vxor.vv_LMUL4SEW64 \
  vxor.vv_LMUL4SEW8 \
  vxor.vv_LMUL8SEW16 \
  vxor.vv_LMUL8SEW32 \
  vxor.vv_LMUL8SEW64 \
  vxor.vv_LMUL8SEW8 \
  vxor.vx_LMUL1SEW16 \
  vxor.vx_LMUL1SEW32 \
  vxor.vx_LMUL1SEW64 \
  vxor.vx_LMUL1SEW8 \
  vxor.vx_LMUL2SEW16 \
  vxor.vx_LMUL2SEW32 \
  vxor.vx_LMUL2SEW64 \
  vxor.vx_LMUL2SEW8 \
  vxor.vx_LMUL4SEW16 \
  vxor.vx_LMUL4SEW32 \
  vxor.vx_LMUL4SEW64 \
  vxor.vx_LMUL4SEW8 \
  vxor.vx_LMUL8SEW16 \
  vxor.vx_LMUL8SEW32 \
  vxor.vx_LMUL8SEW64 \
  vxor.vx_LMUL8SEW8 \

rv64uv_p_tests = $(addprefix rv64uv-p-, $(rv64uv_sc_tests))
rv64uv_v_tests = $(addprefix rv64uv-v-, $(rv64uv_sc_tests))
