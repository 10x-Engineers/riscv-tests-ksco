
# See LICENSE for license details.

# This file is automatically generated. Do not edit.

#*****************************************************************************
# vsra.vv_LMUL1SEW16.S
#-----------------------------------------------------------------------------
#
# Test vsra.vv insnructions.
# With LMUL=1, SEW=16
#

#include "riscv_test.h"
#include "test_macros.h"

RVTEST_RV64UV

RVTEST_CODE_BEGIN


  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, 8
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, 8
  vsetvli t1, t0, e16,m1,tu,ma
  vsra.vv v1, v2, v3

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 8
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3, v0.t

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 8
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3, v0.t

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, 15
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, 15
  vsetvli t1, t0, e16,m1,tu,ma
  vsra.vv v1, v2, v3

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 15
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3, v0.t

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 15
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3, v0.t

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, 16
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, 16
  vsetvli t1, t0, e16,m1,tu,ma
  vsra.vv v1, v2, v3

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 16
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3, v0.t

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a2, tdat
  vle16.v v2, (a2)

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v1, (a2)
  la a2, tdat+8

  vsetvli t1, t0, e16,m1,ta,ma
  vle16.v v3, (a2)

  
  li t0, -1
  vsetvli t1, t0, e8,m1,ta,ma
  la a3, mask
  vle8.v v0, (a3)

  li t0, 16
  vsetvli t1, t0, e16,m1,ta,ma
  vsra.vv v1, v2, v3, v0.t

  li t0, -1
  vsetvli t1, t0, e16,m1,ta,ma
  la a1, res
  vse16.v v1, (a1)

  addi x0, x1, 2


  TEST_CASE(2, x0, 0x0)
  TEST_PASSFAIL

RVTEST_CODE_END

  .data
RVTEST_DATA_BEGIN

res:
  .zero 144

tdat:
  .quad 0x10003fff8
  .quad 0x100070000
  .quad 0xffffefffefffffff
  .quad 0x1000000010000
  .quad 0x10003fff8
  .quad 0x100070000
  .quad 0xffffefffefffffff
  .quad 0x1000000010000
  .quad 0x10003fff8

mask:
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555
  .quad 0x5555555555555555

RVTEST_DATA_END
